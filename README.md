# Speech-Emotion-Recognition---Sound-Classification

Emotion Recognition from Audio Using Deep Learning

This project uses deep learning to recognize emotions from audio files. It processes speech samples, extracts MFCC features, and trains a neural network model to classify emotions like happy, sad, angry, and more.

#Key Features:

End-to-end workflow for emotion recognition using Python

Audio data preprocessing and MFCC feature extraction

Neural network model built with Keras/TensorFlow

Predicts emotions on new, unseen audio samples

Easy to adapt for custom datasets and use cases

#Technologies Used:
Python, Pandas, NumPy, Librosa, Scikit-learn, Keras/TensorFlow

#How It Works:

Loads labeled audio data

Extracts key sound features (MFCCs)

Trains and evaluates a deep learning model

Accepts new audio inputs for emotion prediction

This notebook demonstrates practical machine learning for speech emotion recognition, and can be extended for real-world applications such as human-computer interaction, call center analytics, or health tech.
